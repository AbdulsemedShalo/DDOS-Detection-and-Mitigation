{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEt1Wv8Q/30pl+ozXzHE/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulsemedShalo/DDOS-Detection-and-Mitigation/blob/main/FeatureOrder1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAJ9tXIP3bYO",
        "outputId": "d5f041c9-ceb9-4ffa-f60f-f2712f5b9198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error: 0.0\n",
            "Features in order of importance:\n",
            "Label\n",
            "Max_Packet_Length\n",
            "Fwd_Packet_Length_Max\n",
            "Flow_Packets_Sec\n",
            "Flow_Bytes_Sec\n",
            "Packet_Length_Variance\n",
            "Packet_Length_Std\n",
            "Flow_IAT_Max\n",
            "Subflow_Fwd_Bytes\n",
            "Fwd_IAT_Max\n",
            "min_seg_size_forward\n",
            "Fwd_Packet_Length_Std\n",
            "Bwd_Packets_Sec\n",
            "Init_Win_bytes_backward\n",
            "Packet_Length_Mean\n",
            "Average_Packet_Size\n",
            "Flow_IAT_Std\n",
            "Fwd_IAT_Total\n",
            "Fwd_IAT_Std\n",
            "Avg_Fwd_Segment_Size\n",
            "Fwd_Packet_Length_Mean\n",
            "Fwd_Header_Length\n",
            "Fwd_IAT_Mean\n",
            "Flow_IAT_Mean\n",
            "Idle_Max\n",
            "Idle_Mean\n",
            "Fwd_Packets_Sec\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/AbdulsemedShalo/DDOS-Detection-and-Mitigation/main/Dataset.csv')\n",
        "\n",
        "# because ip addresses are string can't be converted to int to train, drop them.\n",
        "data = data.drop(\"Source.IP\", axis=1)\n",
        "data = data.drop(\"Destination.IP\", axis=1)\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "# Extraxt the features you want to base the foundation of our model training\n",
        "features = ['Max_Packet_Length','Fwd_Packet_Length_Max','Flow_Packets_Sec','Flow_Bytes_Sec','Packet_Length_Std'\n",
        "           ,'Packet_Length_Variance','Flow_IAT_Max','Fwd_IAT_Max','Subflow_Fwd_Bytes','Fwd_Packet_Length_Std'\n",
        "           ,'Bwd_Packets_Sec','min_seg_size_forward','Init_Win_bytes_backward','Average_Packet_Size'\n",
        "           ,'Packet_Length_Mean','Fwd_IAT_Total','Flow_IAT_Std','Fwd_IAT_Std','Avg_Fwd_Segment_Size'\n",
        "           ,'Fwd_Packet_Length_Mean','Fwd_Header_Length','Fwd_IAT_Mean','Flow_IAT_Mean','Idle_Max'\n",
        "           ,'Idle_Mean','Fwd_Packets_Sec']\n",
        "\n",
        "\n",
        "\n",
        "# Replace missing values with the mean of the column\n",
        "data['Fwd_Packets_Sec'].fillna(data['Fwd_Packets_Sec'].median(), inplace=True)\n",
        "data['Idle_Mean'].fillna(data['Idle_Mean'].median(), inplace=True)\n",
        "data['Idle_Max'].fillna(data['Idle_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Mean'].fillna(data['Flow_IAT_Mean'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_IAT_Mean'].fillna(data['Fwd_IAT_Mean'].median(), inplace=True)\n",
        "data['Fwd_Header_Length'].fillna(data['Fwd_Header_Length'].median(), inplace=True)\n",
        "data['Fwd_Packet_Length_Mean'].fillna(data['Fwd_Packet_Length_Mean'].median(), inplace=True)\n",
        "data['Avg_Fwd_Segment_Size'].fillna(data['Avg_Fwd_Segment_Size'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_IAT_Std'].fillna(data['Fwd_IAT_Std'].median(), inplace=True)\n",
        "data['Fwd_IAT_Total'].fillna(data['Fwd_IAT_Total'].median(), inplace=True)\n",
        "data['Flow_IAT_Std'].fillna(data['Flow_IAT_Std'].median(), inplace=True)\n",
        "data['Packet_Length_Mean'].fillna(data['Packet_Length_Mean'].median(), inplace=True)\n",
        "\n",
        "data['Average_Packet_Size'].fillna(data['Average_Packet_Size'].median(), inplace=True)\n",
        "data['Init_Win_bytes_backward'].fillna(data['Init_Win_bytes_backward'].median(), inplace=True)\n",
        "data['min_seg_size_forward'].fillna(data['min_seg_size_forward'].median(), inplace=True)\n",
        "data['Bwd_Packets_Sec'].fillna(data['Bwd_Packets_Sec'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_Packet_Length_Std'].fillna(data['Fwd_Packet_Length_Std'].median(), inplace=True)\n",
        "data['Subflow_Fwd_Bytes'].fillna(data['Subflow_Fwd_Bytes'].median(), inplace=True)\n",
        "data['Fwd_IAT_Max'].fillna(data['Fwd_IAT_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Max'].fillna(data['Flow_IAT_Max'].median(), inplace=True)\n",
        "\n",
        "data['Packet_Length_Variance'].fillna(data['Packet_Length_Variance'].median(), inplace=True)\n",
        "data['Packet_Length_Std'].fillna(data['Packet_Length_Std'].median(), inplace=True)\n",
        "data['Flow_Bytes_Sec'].fillna(data['Flow_Bytes_Sec'].median(), inplace=True)\n",
        "data['Flow_Packets_Sec'].fillna(data['Flow_Packets_Sec'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_Packet_Length_Max'].fillna(data['Fwd_Packet_Length_Max'].median(), inplace=True)\n",
        "data['Max_Packet_Length'].fillna(data['Max_Packet_Length'].median(), inplace=True)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, data[\"Label\"], test_size=0.2)\n",
        "\n",
        "# Transform the negative feature values to positive values\n",
        "features_positive = X_train.copy()\n",
        "features_positive[features_positive < 0] = 0\n",
        "\n",
        "# Create a logistic regression model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Re-fit the model to the transformed data\n",
        "model.fit(features_positive, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(features_positive)\n",
        "\n",
        "# Evaluate the model performance\n",
        "print('Mean absolute error:', np.mean(np.abs(predictions - y_train)))\n",
        "\n",
        "# Calculate the mutual information between each feature and the labels\n",
        "mi_scores = mutual_info_classif(X_train, y_train)\n",
        "\n",
        "# Sort the features by their mutual information scores\n",
        "sorted_features = np.argsort(mi_scores)\n",
        "\n",
        "# Print the features in order of importance\n",
        "print('Features in order of importance:')\n",
        "for i in sorted_features[::-1]:\n",
        "    print(data.columns[i])\n",
        "\n"
      ]
    }
  ]
}