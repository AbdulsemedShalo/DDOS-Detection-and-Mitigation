{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulsemedShalo/DDOS-Detection-and-Mitigation/blob/main/AccuracyAndConfusionMatrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3VELO4iYsB8",
        "outputId": "e490e5e7-aaf8-4b44-bbee-3b6a0d769aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    3640\n",
            "1    3096\n",
            "2    1262\n",
            "3       1\n",
            "Name: Label, dtype: int64\n",
            "Decision Tree Classiffier Accuracy: 0.960625\n",
            "++++++++++++ Confusion Matrix and Classification report for Decision Tree Classifier ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       750\n",
            "           1       1.00      0.90      0.94       604\n",
            "           2       0.80      1.00      0.89       246\n",
            "\n",
            "    accuracy                           0.96      1600\n",
            "   macro avg       0.93      0.97      0.94      1600\n",
            "weighted avg       0.97      0.96      0.96      1600\n",
            "\n",
            "[[750   0   0]\n",
            " [  0 541  63]\n",
            " [  0   0 246]]\n",
            "****************************************************************************************************\n",
            "Decision Tree with Max Depth Accuracy: 0.99875\n",
            "++++++++++++ Confusion Matrix and Classification report for Decision Tree with Max Depth Classifier ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       750\n",
            "           1       1.00      0.90      0.94       604\n",
            "           2       0.80      1.00      0.89       246\n",
            "\n",
            "    accuracy                           0.96      1600\n",
            "   macro avg       0.93      0.97      0.94      1600\n",
            "weighted avg       0.97      0.96      0.96      1600\n",
            "\n",
            "[[750   0   0]\n",
            " [  0 541  63]\n",
            " [  0   0 246]]\n",
            "*****************************************************************************************************\n",
            "Random Forest Classifier Accuracy: 0.989375\n",
            "++++++++++++ Confusion Matrix and Classification report for Random Forest Classifier ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       750\n",
            "           1       1.00      0.90      0.94       604\n",
            "           2       0.80      1.00      0.89       246\n",
            "\n",
            "    accuracy                           0.96      1600\n",
            "   macro avg       0.93      0.97      0.94      1600\n",
            "weighted avg       0.97      0.96      0.96      1600\n",
            "\n",
            "[[750   0   0]\n",
            " [  0 541  63]\n",
            " [  0   0 246]]\n",
            "*********************************************************************************************************\n",
            "Naive Bayes's  Algorithm Accuracy:  0.915\n",
            "++++++++++++ Confusion Matrix and Classification report for Naive Bayes's  Algorithm ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       750\n",
            "           1       1.00      0.90      0.94       604\n",
            "           2       0.80      1.00      0.89       246\n",
            "\n",
            "    accuracy                           0.96      1600\n",
            "   macro avg       0.93      0.97      0.94      1600\n",
            "weighted avg       0.97      0.96      0.96      1600\n",
            "\n",
            "[[750   0   0]\n",
            " [  0 541  63]\n",
            " [  0   0 246]]\n",
            "*********************************************************************************************************\n",
            "K-Nearest Neighbour Accuracy: 0.969375\n",
            "++++++++++++ Confusion Matrix and Classification report for K-Nearest Neighbour Algorithm ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       750\n",
            "           1       1.00      0.90      0.94       604\n",
            "           2       0.80      1.00      0.89       246\n",
            "\n",
            "    accuracy                           0.96      1600\n",
            "   macro avg       0.93      0.97      0.94      1600\n",
            "weighted avg       0.97      0.96      0.96      1600\n",
            "\n",
            "[[750   0   0]\n",
            " [  0 541  63]\n",
            " [  0   0 246]]\n",
            "*********************************************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression algorithm Accuracy: 0.9325\n",
            "++++++++++++ Confusion Matrix and Classification report for Logistic Regression algorithm ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95       750\n",
            "           1       0.95      0.87      0.91       604\n",
            "           2       0.92      0.93      0.92       246\n",
            "\n",
            "    accuracy                           0.93      1600\n",
            "   macro avg       0.93      0.93      0.93      1600\n",
            "weighted avg       0.93      0.93      0.93      1600\n",
            "\n",
            "[[741   7   2]\n",
            " [ 64 523  17]\n",
            " [  0  18 228]]\n",
            "*********************************************************************************************************\n",
            "SVM Classifier Accuracy: 0.97\n",
            "++++++++++++ Confusion Matrix and Classification report for SVM algorithm +++++++++++++++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       750\n",
            "           1       0.95      0.98      0.96       604\n",
            "           2       0.98      0.95      0.96       246\n",
            "\n",
            "    accuracy                           0.97      1600\n",
            "   macro avg       0.97      0.97      0.97      1600\n",
            "weighted avg       0.97      0.97      0.97      1600\n",
            "\n",
            "[[726  21   3]\n",
            " [ 10 592   2]\n",
            " [  1  11 234]]\n",
            "*********************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "DatasetUrl = 'https://raw.githubusercontent.com/GutemaB2015/DDOS-Detection-and-Mitigation/main/FullDataset.csv'\n",
        "data = pd.read_csv(DatasetUrl)\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
        "data['Label'].fillna(data['Label'].median(), inplace=True)\n",
        "\n",
        "\n",
        "AttackLabel = data[\"Label\"]\n",
        "\n",
        "data = data.drop(\"Label\", axis=1)\n",
        "\n",
        "\n",
        "\n",
        "data = data.drop(\"Source.IP\", axis=1)\n",
        "data = data.drop(\"Source.Port\", axis=1)\n",
        "data = data.drop(\"Destination.Port\", axis=1)\n",
        "data = data.drop(\"Destination.IP\", axis=1)\n",
        "\n",
        "\n",
        "data = data.drop(\"Total_Length_of_Bwd_Packets\", axis=1)\n",
        "data = data.drop(\"Fwd_Packet_Length_Min\", axis=1)\n",
        "data = data.drop(\"Bwd_Packet_Length_Max\", axis=1)\n",
        "data = data.drop(\"Bwd_Packet_Length_Min\", axis=1)\n",
        "\n",
        "data = data.drop(\"Bwd_Packet_Length_Mean\", axis=1)\n",
        "data = data.drop(\"Bwd_Packet_Length_Std\", axis=1)\n",
        "data = data.drop(\"Flow_IAT_Min\", axis=1)\n",
        "data = data.drop(\"Fwd_IAT_Min\", axis=1)\n",
        "\n",
        "data = data.drop(\"Bwd_IAT_Total\", axis=1)\n",
        "data = data.drop(\"Bwd_IAT_Mean\", axis=1)\n",
        "data = data.drop(\"Bwd_IAT_Std\", axis=1)\n",
        "data = data.drop(\"Bwd_IAT_Max\", axis=1)\n",
        "\n",
        "data = data.drop(\"Bwd_IAT_Min\", axis=1)\n",
        "data = data.drop(\"Bwd_Header_Length\", axis=1)\n",
        "data = data.drop(\"Min_Packet_Length\", axis=1)\n",
        "data = data.drop(\"SYN_Flag_Count\", axis=1)\n",
        "\n",
        "\n",
        "data = data.drop(\"Down_Up_Ratio\", axis=1)\n",
        "data = data.drop(\"Avg_Bwd_Segment_Size\", axis=1)\n",
        "data = data.drop(\"Subflow_Fwd_Packets\", axis=1)\n",
        "data = data.drop(\"Subflow_Bwd_Packets\", axis=1)\n",
        "\n",
        "\n",
        "data = data.drop(\"Subflow_Bwd_Bytes\", axis=1)\n",
        "data = data.drop(\"Init_Win_bytes_forward\", axis=1)\n",
        "data = data.drop(\"act_data_pkt_fwd\", axis=1)\n",
        "data = data.drop(\"Active_Mean\", axis=1)\n",
        "\n",
        "\n",
        "data = data.drop(\"Idle_Std\", axis=1)\n",
        "data = data.drop(\"Idle_Min\", axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Get the number of frequencies\n",
        "num_frequencies = AttackLabel.value_counts()\n",
        "print(num_frequencies)\n",
        "\n",
        "# Extraxt the features you want to base the foundation of our model training\n",
        "features = ['Max_Packet_Length','Fwd_Packet_Length_Max','Flow_Packets_Sec','Flow_Bytes_Sec','Packet_Length_Std'\n",
        "           ,'Packet_Length_Variance','Flow_IAT_Max','Fwd_IAT_Max','Subflow_Fwd_Bytes','Fwd_Packet_Length_Std'\n",
        "           ,'Bwd_Packets_Sec','min_seg_size_forward','Init_Win_bytes_backward','Average_Packet_Size'\n",
        "           ,'Packet_Length_Mean','Fwd_IAT_Total','Flow_IAT_Std','Fwd_IAT_Std','Avg_Fwd_Segment_Size'\n",
        "           ,'Fwd_Packet_Length_Mean','Fwd_Header_Length','Fwd_IAT_Mean','Flow_IAT_Mean','Idle_Max'\n",
        "           ,'Idle_Mean','Fwd_Packets_Sec','Active_Std','Active_Max','Active_Min']\n",
        "\n",
        "\n",
        "# Replace missing values with the mean of the column\n",
        "data['Fwd_Packets_Sec'].fillna(data['Fwd_Packets_Sec'].median(), inplace=True)\n",
        "data['Idle_Mean'].fillna(data['Idle_Mean'].median(), inplace=True)\n",
        "data['Idle_Max'].fillna(data['Idle_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Mean'].fillna(data['Flow_IAT_Mean'].median(), inplace=True)\n",
        "\n",
        "\n",
        "data['Active_Std'].fillna(data['Active_Std'].median(), inplace=True)\n",
        "data['Active_Max'].fillna(data['Active_Max'].median(), inplace=True)\n",
        "data['Active_Min'].fillna(data['Active_Min'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_IAT_Mean'].fillna(data['Fwd_IAT_Mean'].median(), inplace=True)\n",
        "data['Fwd_Header_Length'].fillna(data['Fwd_Header_Length'].median(), inplace=True)\n",
        "data['Fwd_Packet_Length_Mean'].fillna(data['Fwd_Packet_Length_Mean'].median(), inplace=True)\n",
        "data['Avg_Fwd_Segment_Size'].fillna(data['Avg_Fwd_Segment_Size'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_IAT_Std'].fillna(data['Fwd_IAT_Std'].median(), inplace=True)\n",
        "data['Fwd_IAT_Total'].fillna(data['Fwd_IAT_Total'].median(), inplace=True)\n",
        "data['Flow_IAT_Std'].fillna(data['Flow_IAT_Std'].median(), inplace=True)\n",
        "data['Packet_Length_Mean'].fillna(data['Packet_Length_Mean'].median(), inplace=True)\n",
        "\n",
        "data['Average_Packet_Size'].fillna(data['Average_Packet_Size'].median(), inplace=True)\n",
        "data['Init_Win_bytes_backward'].fillna(data['Init_Win_bytes_backward'].median(), inplace=True)\n",
        "data['min_seg_size_forward'].fillna(data['min_seg_size_forward'].median(), inplace=True)\n",
        "data['Bwd_Packets_Sec'].fillna(data['Bwd_Packets_Sec'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_Packet_Length_Std'].fillna(data['Fwd_Packet_Length_Std'].median(), inplace=True)\n",
        "data['Subflow_Fwd_Bytes'].fillna(data['Subflow_Fwd_Bytes'].median(), inplace=True)\n",
        "data['Fwd_IAT_Max'].fillna(data['Fwd_IAT_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Max'].fillna(data['Flow_IAT_Max'].median(), inplace=True)\n",
        "\n",
        "data['Packet_Length_Variance'].fillna(data['Packet_Length_Variance'].median(), inplace=True)\n",
        "data['Packet_Length_Std'].fillna(data['Packet_Length_Std'].median(), inplace=True)\n",
        "data['Flow_Bytes_Sec'].fillna(data['Flow_Bytes_Sec'].median(), inplace=True)\n",
        "data['Flow_Packets_Sec'].fillna(data['Flow_Packets_Sec'].median(), inplace=True)\n",
        "data['Fwd_Packet_Length_Max'].fillna(data['Fwd_Packet_Length_Max'].median(), inplace=True)\n",
        "data['Max_Packet_Length'].fillna(data['Max_Packet_Length'].median(), inplace=True)\n",
        "\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], AttackLabel, test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#DEscision Tree Accuracy\n",
        "dectreClassifier = DecisionTreeClassifier(max_depth=2)\n",
        "dectreClassifier = dectreClassifier.fit(X_train,y_train)\n",
        "y_pred = dectreClassifier.predict(X_test)\n",
        "print(\"Decision Tree Classiffier Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Decision Tree Classifier ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"****************************************************************************************************\")\n",
        "\n",
        "# Decision Tree with Max Depth 3\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "clf = clf.fit(X_train,y_train)\n",
        "dt_pred1 = clf.predict(X_test)\n",
        "print(\"Decision Tree with Max Depth Accuracy:\",metrics.accuracy_score(y_test, dt_pred1))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Decision Tree with Max Depth Classifier ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*****************************************************************************************************\")\n",
        "\n",
        "# Create a logistic regression model\n",
        "rmfClassifier = RandomForestClassifier(n_estimators=100, random_state=0, max_depth=2)\n",
        "rmfClassifier.fit(X_train, y_train)\n",
        "predictions = rmfClassifier.predict(X_test)\n",
        "print('Random Forest Classifier Accuracy:', rmfClassifier.score(X_test, y_test))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Random Forest Classifier ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "# create gaussian naive bayes classifier\n",
        "naiveBayes = GaussianNB()\n",
        "naiveBayes.fit(X_train,y_train)\n",
        "naiveBayesPreddiction = naiveBayes.predict(X_test)\n",
        "print(\"Naive Bayes's  Algorithm Accuracy: \",metrics.accuracy_score(y_test,naiveBayesPreddiction))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Naive Bayes's  Algorithm ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "\n",
        "#K-Nearest Neighbour Algorithm\n",
        "knClassifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knClassifier.fit(X_train, y_train)\n",
        "predictions = knClassifier.predict(X_test)\n",
        "print('K-Nearest Neighbour Accuracy:', knClassifier.score(X_test, y_test))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for K-Nearest Neighbour Algorithm ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "# Logistic Regression algorithm\n",
        "logRegression = LogisticRegression()\n",
        "logRegression.fit(X_train, y_train)\n",
        "y_pred = logRegression.predict(X_test)\n",
        "print(\"Logistic Regression algorithm Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Logistic Regression algorithm ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "\n",
        "# Create an SVM classifier\n",
        "svmClassifier = SVC(kernel='rbf', C = 70)\n",
        "svmClassifier.fit(X_train, y_train)\n",
        "y_pred = svmClassifier.predict(X_test)\n",
        "print(\"SVM Classifier Accuracy:\", svmClassifier.score(X_test, y_test))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for SVM algorithm +++++++++++++++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}