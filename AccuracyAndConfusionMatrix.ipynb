{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaHyu+NITk29+wb0DSgkRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulsemedShalo/DDOS-Detection-and-Mitigation/blob/main/AccuracyAndConfusionMatrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3VELO4iYsB8",
        "outputId": "6ccf5a98-ec4a-4fb8-bd05-5ea5836f9842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BENIGN           13660\n",
            "DoS Hulk         11663\n",
            "DoS slowloris     4676\n",
            "Name: Label, dtype: int64\n",
            "Decision Tree Classiffier Accuracy: 0.9998333333333334\n",
            "++++++++++++ Confusion Matrix and Classification report for Decision Tree Classifier ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2707\n",
            "           1       1.00      1.00      1.00      2330\n",
            "           2       1.00      1.00      1.00       963\n",
            "\n",
            "    accuracy                           1.00      6000\n",
            "   macro avg       1.00      1.00      1.00      6000\n",
            "weighted avg       1.00      1.00      1.00      6000\n",
            "\n",
            "[[2707    0    0]\n",
            " [   0 2329    1]\n",
            " [   0    0  963]]\n",
            "****************************************************************************************************\n",
            "Decision Tree with Max Depth Accuracy: 0.9968333333333333\n",
            "++++++++++++ Confusion Matrix and Classification report for Decision Tree with Max Depth Classifier ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2707\n",
            "           1       1.00      1.00      1.00      2330\n",
            "           2       1.00      1.00      1.00       963\n",
            "\n",
            "    accuracy                           1.00      6000\n",
            "   macro avg       1.00      1.00      1.00      6000\n",
            "weighted avg       1.00      1.00      1.00      6000\n",
            "\n",
            "[[2707    0    0]\n",
            " [   0 2329    1]\n",
            " [   0    0  963]]\n",
            "*****************************************************************************************************\n",
            "Random Forest Classifier Accuracy: 1.0\n",
            "++++++++++++ Confusion Matrix and Classification report for Random Forest Classifier ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2707\n",
            "           1       1.00      1.00      1.00      2330\n",
            "           2       1.00      1.00      1.00       963\n",
            "\n",
            "    accuracy                           1.00      6000\n",
            "   macro avg       1.00      1.00      1.00      6000\n",
            "weighted avg       1.00      1.00      1.00      6000\n",
            "\n",
            "[[2707    0    0]\n",
            " [   0 2329    1]\n",
            " [   0    0  963]]\n",
            "*********************************************************************************************************\n",
            "Naive Bayes's  Algorithm Accuracy:  0.9243333333333333\n",
            "++++++++++++ Confusion Matrix and Classification report for Naive Bayes's  Algorithm ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2707\n",
            "           1       1.00      1.00      1.00      2330\n",
            "           2       1.00      1.00      1.00       963\n",
            "\n",
            "    accuracy                           1.00      6000\n",
            "   macro avg       1.00      1.00      1.00      6000\n",
            "weighted avg       1.00      1.00      1.00      6000\n",
            "\n",
            "[[2707    0    0]\n",
            " [   0 2329    1]\n",
            " [   0    0  963]]\n",
            "*********************************************************************************************************\n",
            "K-Nearest Neighbour Accuracy: 0.976\n",
            "++++++++++++ Confusion Matrix and Classification report for K-Nearest Neighbour Algorithm ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2707\n",
            "           1       1.00      1.00      1.00      2330\n",
            "           2       1.00      1.00      1.00       963\n",
            "\n",
            "    accuracy                           1.00      6000\n",
            "   macro avg       1.00      1.00      1.00      6000\n",
            "weighted avg       1.00      1.00      1.00      6000\n",
            "\n",
            "[[2707    0    0]\n",
            " [   0 2329    1]\n",
            " [   0    0  963]]\n",
            "*********************************************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression algorithm Accuracy: 0.9246666666666666\n",
            "++++++++++++ Confusion Matrix and Classification report for Logistic Regression algorithm ++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94      2707\n",
            "           1       0.96      0.86      0.91      2330\n",
            "           2       0.92      0.89      0.91       963\n",
            "\n",
            "    accuracy                           0.92      6000\n",
            "   macro avg       0.93      0.91      0.92      6000\n",
            "weighted avg       0.93      0.92      0.92      6000\n",
            "\n",
            "[[2678   21    8]\n",
            " [ 254 2011   65]\n",
            " [  31   73  859]]\n",
            "*********************************************************************************************************\n",
            "SVM Classifier Accuracy: 0.7503333333333333\n",
            "++++++++++++ Confusion Matrix and Classification report for SVM algorithm +++++++++++++++++++++++++++++\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.97      0.78      2707\n",
            "           1       0.91      0.42      0.57      2330\n",
            "           2       0.97      0.93      0.95       963\n",
            "\n",
            "    accuracy                           0.75      6000\n",
            "   macro avg       0.85      0.77      0.77      6000\n",
            "weighted avg       0.81      0.75      0.73      6000\n",
            "\n",
            "[[2636   65    6]\n",
            " [1334  972   24]\n",
            " [  43   26  894]]\n",
            "*********************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "DatasetUrl = 'https://raw.githubusercontent.com/AbdulsemedShalo/DDOS-Detection-and-Mitigation/main/Dataset.csv'\n",
        "data = pd.read_csv(DatasetUrl)\n",
        "\n",
        "data = data.drop(\"Source.IP\", axis=1)\n",
        "data = data.drop(\"Destination.IP\", axis=1)\n",
        "\n",
        "# Get the number of frequencies\n",
        "num_frequencies = data['Label'].value_counts()\n",
        "# Print the number of frequencies\n",
        "print(num_frequencies)\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Label'] = label_encoder.fit_transform(data['Label'])\n",
        "\n",
        "# Extraxt the features you want to base the foundation of our model training\n",
        "features = ['Max_Packet_Length','Fwd_Packet_Length_Max','Flow_Packets_Sec','Flow_Bytes_Sec','Packet_Length_Std'\n",
        "           ,'Packet_Length_Variance','Flow_IAT_Max','Fwd_IAT_Max','Subflow_Fwd_Bytes','Fwd_Packet_Length_Std'\n",
        "           ,'Bwd_Packets_Sec','min_seg_size_forward','Init_Win_bytes_backward','Average_Packet_Size'\n",
        "           ,'Packet_Length_Mean','Fwd_IAT_Total','Flow_IAT_Std','Fwd_IAT_Std','Avg_Fwd_Segment_Size'\n",
        "           ,'Fwd_Packet_Length_Mean','Fwd_Header_Length','Fwd_IAT_Mean','Flow_IAT_Mean','Idle_Max'\n",
        "           ,'Idle_Mean','Fwd_Packets_Sec']\n",
        "\n",
        "\n",
        "# Replace missing values with the mean of the column\n",
        "data['Fwd_Packets_Sec'].fillna(data['Fwd_Packets_Sec'].median(), inplace=True)\n",
        "data['Idle_Mean'].fillna(data['Idle_Mean'].median(), inplace=True)\n",
        "data['Idle_Max'].fillna(data['Idle_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Mean'].fillna(data['Flow_IAT_Mean'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_IAT_Mean'].fillna(data['Fwd_IAT_Mean'].median(), inplace=True)\n",
        "data['Fwd_Header_Length'].fillna(data['Fwd_Header_Length'].median(), inplace=True)\n",
        "data['Fwd_Packet_Length_Mean'].fillna(data['Fwd_Packet_Length_Mean'].median(), inplace=True)\n",
        "data['Avg_Fwd_Segment_Size'].fillna(data['Avg_Fwd_Segment_Size'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_IAT_Std'].fillna(data['Fwd_IAT_Std'].median(), inplace=True)\n",
        "data['Fwd_IAT_Total'].fillna(data['Fwd_IAT_Total'].median(), inplace=True)\n",
        "data['Flow_IAT_Std'].fillna(data['Flow_IAT_Std'].median(), inplace=True)\n",
        "data['Packet_Length_Mean'].fillna(data['Packet_Length_Mean'].median(), inplace=True)\n",
        "\n",
        "data['Average_Packet_Size'].fillna(data['Average_Packet_Size'].median(), inplace=True)\n",
        "data['Init_Win_bytes_backward'].fillna(data['Init_Win_bytes_backward'].median(), inplace=True)\n",
        "data['min_seg_size_forward'].fillna(data['min_seg_size_forward'].median(), inplace=True)\n",
        "data['Bwd_Packets_Sec'].fillna(data['Bwd_Packets_Sec'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_Packet_Length_Std'].fillna(data['Fwd_Packet_Length_Std'].median(), inplace=True)\n",
        "data['Subflow_Fwd_Bytes'].fillna(data['Subflow_Fwd_Bytes'].median(), inplace=True)\n",
        "data['Fwd_IAT_Max'].fillna(data['Fwd_IAT_Max'].median(), inplace=True)\n",
        "data['Flow_IAT_Max'].fillna(data['Flow_IAT_Max'].median(), inplace=True)\n",
        "\n",
        "data['Packet_Length_Variance'].fillna(data['Packet_Length_Variance'].median(), inplace=True)\n",
        "data['Packet_Length_Std'].fillna(data['Packet_Length_Std'].median(), inplace=True)\n",
        "data['Flow_Bytes_Sec'].fillna(data['Flow_Bytes_Sec'].median(), inplace=True)\n",
        "data['Flow_Packets_Sec'].fillna(data['Flow_Packets_Sec'].median(), inplace=True)\n",
        "\n",
        "data['Fwd_Packet_Length_Max'].fillna(data['Fwd_Packet_Length_Max'].median(), inplace=True)\n",
        "data['Max_Packet_Length'].fillna(data['Max_Packet_Length'].median(), inplace=True)\n",
        "\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[\"Label\"], test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#DEscision Tree Accuracy\n",
        "dectreClassifier = DecisionTreeClassifier()\n",
        "dectreClassifier = dectreClassifier.fit(X_train,y_train)\n",
        "y_pred = dectreClassifier.predict(X_test)\n",
        "print(\"Decision Tree Classiffier Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Decision Tree Classifier ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"****************************************************************************************************\")\n",
        "\n",
        "# Decision Tree with Max Depth 3\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "clf = clf.fit(X_train,y_train)\n",
        "dt_pred1 = clf.predict(X_test)\n",
        "print(\"Decision Tree with Max Depth Accuracy:\",metrics.accuracy_score(y_test, dt_pred1))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Decision Tree with Max Depth Classifier ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*****************************************************************************************************\")\n",
        "\n",
        "# Create a logistic regression model\n",
        "rmfClassifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rmfClassifier.fit(X_train, y_train)\n",
        "predictions = rmfClassifier.predict(X_test)\n",
        "print('Random Forest Classifier Accuracy:', rmfClassifier.score(X_test, y_test))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Random Forest Classifier ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "# create gaussian naive bayes classifier\n",
        "naiveBayes = GaussianNB()\n",
        "naiveBayes.fit(X_train,y_train)\n",
        "naiveBayesPreddiction = naiveBayes.predict(X_test)\n",
        "print(\"Naive Bayes's  Algorithm Accuracy: \",metrics.accuracy_score(y_test,naiveBayesPreddiction))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Naive Bayes's  Algorithm ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "\n",
        "#K-Nearest Neighbour Algorithm\n",
        "knClassifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knClassifier.fit(X_train, y_train)\n",
        "predictions = knClassifier.predict(X_test)\n",
        "print('K-Nearest Neighbour Accuracy:', knClassifier.score(X_test, y_test))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for K-Nearest Neighbour Algorithm ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "# Logistic Regression algorithm\n",
        "logRegression = LogisticRegression()\n",
        "logRegression.fit(X_train, y_train)\n",
        "y_pred = logRegression.predict(X_test)\n",
        "print(\"Logistic Regression algorithm Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for Logistic Regression algorithm ++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "\n",
        "# Create an SVM classifier\n",
        "svmClassifier = svm.SVC(kernel='rbf')\n",
        "svmClassifier.fit(X_train, y_train)\n",
        "y_pred = svmClassifier.predict(X_test)\n",
        "print(\"SVM Classifier Accuracy:\", svmClassifier.score(X_test, y_test))\n",
        "print(\"++++++++++++ Confusion Matrix and Classification report for SVM algorithm +++++++++++++++++++++++++++++\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"*********************************************************************************************************\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}